{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import quandl\n",
    "import numpy as np\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = quandl.get('BCHARTS/BITFINEXUSD') -> OLD BUGGY DATASET (OBD)\n",
    "data = quandl.get('BITFINEX/BTCUSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Mid</th>\n",
       "      <th>Last</th>\n",
       "      <th>Bid</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-04-15</th>\n",
       "      <td>513.9000</td>\n",
       "      <td>452.00</td>\n",
       "      <td>504.23500</td>\n",
       "      <td>505.0000</td>\n",
       "      <td>503.5000</td>\n",
       "      <td>504.97</td>\n",
       "      <td>21013.584774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-16</th>\n",
       "      <td>547.0000</td>\n",
       "      <td>495.00</td>\n",
       "      <td>537.50000</td>\n",
       "      <td>538.0000</td>\n",
       "      <td>537.0000</td>\n",
       "      <td>538.00</td>\n",
       "      <td>29633.358705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-17</th>\n",
       "      <td>538.5000</td>\n",
       "      <td>486.10</td>\n",
       "      <td>507.02000</td>\n",
       "      <td>508.0000</td>\n",
       "      <td>506.0400</td>\n",
       "      <td>508.00</td>\n",
       "      <td>20709.783819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-18</th>\n",
       "      <td>509.0000</td>\n",
       "      <td>474.25</td>\n",
       "      <td>483.77000</td>\n",
       "      <td>482.7500</td>\n",
       "      <td>482.7500</td>\n",
       "      <td>484.79</td>\n",
       "      <td>10458.045243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-19</th>\n",
       "      <td>513.9899</td>\n",
       "      <td>473.83</td>\n",
       "      <td>505.01065</td>\n",
       "      <td>507.4999</td>\n",
       "      <td>502.5313</td>\n",
       "      <td>507.49</td>\n",
       "      <td>8963.618369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                High     Low        Mid      Last       Bid     Ask  \\\n",
       "Date                                                                  \n",
       "2014-04-15  513.9000  452.00  504.23500  505.0000  503.5000  504.97   \n",
       "2014-04-16  547.0000  495.00  537.50000  538.0000  537.0000  538.00   \n",
       "2014-04-17  538.5000  486.10  507.02000  508.0000  506.0400  508.00   \n",
       "2014-04-18  509.0000  474.25  483.77000  482.7500  482.7500  484.79   \n",
       "2014-04-19  513.9899  473.83  505.01065  507.4999  502.5313  507.49   \n",
       "\n",
       "                  Volume  \n",
       "Date                      \n",
       "2014-04-15  21013.584774  \n",
       "2014-04-16  29633.358705  \n",
       "2014-04-17  20709.783819  \n",
       "2014-04-18  10458.045243  \n",
       "2014-04-19   8963.618369  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape before embedding: (1336, 7)\n",
      "data shape after embedding: (1321, 15, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"data shape before embedding:\",data.shape)\n",
    "\n",
    "mean = data.mean(axis=0)\n",
    "std = data.std(axis=0)\n",
    "\n",
    "# zscore normalization\n",
    "data = ( data - mean ) / std\n",
    "\n",
    "# # of days past we want skynet to see\n",
    "d = 15\n",
    "\n",
    "X = np.zeros((data.shape[0],d,7))\n",
    "\n",
    "# embedding d days in each DP (deslocamento)\n",
    "for i in range(d,data.shape[0]):\n",
    "    X[i,:,:] = data.iloc[i-d:i].values\n",
    "\n",
    "#removing first d lines, this ones didn't have d days past\n",
    "X = X[d:,:,:]\n",
    "\n",
    "print(\"data shape after embedding:\",X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1336,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating labels\n",
    "Y = data['Mid'] - data.shift(1)['Mid']\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y > 0\n",
    "\n",
    "#removing first line: second label refers to first DP ($$ delta)\n",
    "Y = Y[1:]\n",
    "\n",
    "#removing first d days because of the embedding\n",
    "Y = Y[d:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing last registry from X, since we had to remove first DP from Y\n",
    "#specifying other dimensions for good practices - TY @lucasosouza\n",
    "X = X[: -1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1320,), (1320, 15, 7))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shapes\n",
    "Y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1320, 15, 7, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding channel layer, as expected by the convnet\n",
    "X = X.reshape((Y.shape[0],d,7,1))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "#X_train = X[:-300,:,:,:]\n",
    "#X_test = X[-300:,:,:,:]\n",
    "#Y_train = Y[:-300]\n",
    "#Y_test = Y[-300:]\n",
    "\n",
    "# split the data \n",
    "kf = KFold(n_splits=8,shuffle=True,random_state=0)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #padding same so we dont lose size\n",
    "    X = Conv2D(10,(3,3), strides=(1,1),name=\"conv0\", padding=\"same\")(X_input)\n",
    "    X = BatchNormalization(axis=3,name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = MaxPooling2D((2,2),name='max_pool0')(X)\n",
    "    \n",
    "    #Second conv\n",
    "    X = Conv2D(30,(2,2), strides=(1,1),name=\"conv1\", padding=\"same\")(X)\n",
    "    X = BatchNormalization(axis=3,name='bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = MaxPooling2D((2,2),name='max_pool1')(X)\n",
    "    \n",
    "    #Third conv\n",
    "    X = Conv2D(50,(1,1), strides=(1,1),name=\"conv2\", padding=\"same\")(X)\n",
    "    X = BatchNormalization(axis=3,name='bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #fcs\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(200,activation=\"relu\")(X)\n",
    "    X = Dropout(rate=0.3, seed=0)(X)\n",
    "    X = Dense(100,activation=\"relu\")(X)\n",
    "    X = Dropout(rate=0.3, seed=0)(X)\n",
    "    X = Dense(50,activation=\"relu\")(X)\n",
    "    X = Dropout(rate=0.3, seed=0)(X)\n",
    "    X = Dense(1,activation=\"sigmoid\")(X)\n",
    "    \n",
    "    model = Model(inputs=X_input,outputs=X, name=\"model1\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1155/1155 [==============================] - 1s 999us/step - loss: 0.7125 - acc: 0.5229\n",
      "Epoch 2/300\n",
      "1155/1155 [==============================] - 1s 729us/step - loss: 0.7082 - acc: 0.5065\n",
      "Epoch 3/300\n",
      "1155/1155 [==============================] - 1s 727us/step - loss: 0.7011 - acc: 0.4892\n",
      "Epoch 4/300\n",
      "1155/1155 [==============================] - 1s 734us/step - loss: 0.7018 - acc: 0.5281\n",
      "Epoch 5/300\n",
      "1155/1155 [==============================] - 1s 731us/step - loss: 0.6961 - acc: 0.5177\n",
      "Epoch 6/300\n",
      "1155/1155 [==============================] - 1s 848us/step - loss: 0.6957 - acc: 0.5420\n",
      "Epoch 7/300\n",
      "1155/1155 [==============================] - 1s 773us/step - loss: 0.6889 - acc: 0.5411\n",
      "Epoch 8/300\n",
      "1155/1155 [==============================] - 1s 771us/step - loss: 0.7014 - acc: 0.5013\n",
      "Epoch 9/300\n",
      "1155/1155 [==============================] - 1s 796us/step - loss: 0.6931 - acc: 0.5212\n",
      "Epoch 10/300\n",
      "1155/1155 [==============================] - 1s 751us/step - loss: 0.6925 - acc: 0.5316\n",
      "Epoch 11/300\n",
      "1155/1155 [==============================] - 1s 819us/step - loss: 0.6902 - acc: 0.5325\n",
      "Epoch 12/300\n",
      "1155/1155 [==============================] - 1s 935us/step - loss: 0.6865 - acc: 0.5377\n",
      "Epoch 13/300\n",
      "1155/1155 [==============================] - 1s 834us/step - loss: 0.6946 - acc: 0.5299\n",
      "Epoch 14/300\n",
      "1155/1155 [==============================] - 1s 728us/step - loss: 0.6919 - acc: 0.5359\n",
      "Epoch 15/300\n",
      "1155/1155 [==============================] - 1s 745us/step - loss: 0.6896 - acc: 0.5420\n",
      "Epoch 16/300\n",
      "1155/1155 [==============================] - 1s 814us/step - loss: 0.6875 - acc: 0.5550\n",
      "Epoch 17/300\n",
      "1155/1155 [==============================] - 1s 741us/step - loss: 0.6917 - acc: 0.5307\n",
      "Epoch 18/300\n",
      "1155/1155 [==============================] - 1s 746us/step - loss: 0.6951 - acc: 0.5359\n",
      "Epoch 19/300\n",
      "1155/1155 [==============================] - 1s 835us/step - loss: 0.6913 - acc: 0.5273\n",
      "Epoch 20/300\n",
      "1155/1155 [==============================] - 1s 869us/step - loss: 0.6853 - acc: 0.5437\n",
      "Epoch 21/300\n",
      "1155/1155 [==============================] - 1s 785us/step - loss: 0.6864 - acc: 0.5403\n",
      "Epoch 22/300\n",
      "1155/1155 [==============================] - 1s 899us/step - loss: 0.6891 - acc: 0.5489\n",
      "Epoch 23/300\n",
      "1155/1155 [==============================] - 1s 889us/step - loss: 0.6868 - acc: 0.5584\n",
      "Epoch 24/300\n",
      "1155/1155 [==============================] - 1s 824us/step - loss: 0.6837 - acc: 0.5532\n",
      "Epoch 25/300\n",
      "1155/1155 [==============================] - 1s 846us/step - loss: 0.6855 - acc: 0.5455\n",
      "Epoch 26/300\n",
      "1155/1155 [==============================] - 1s 982us/step - loss: 0.6804 - acc: 0.5567\n",
      "Epoch 27/300\n",
      "1155/1155 [==============================] - 1s 996us/step - loss: 0.6795 - acc: 0.5576\n",
      "Epoch 28/300\n",
      "1155/1155 [==============================] - 1s 828us/step - loss: 0.6793 - acc: 0.5515\n",
      "Epoch 29/300\n",
      "1155/1155 [==============================] - 1s 770us/step - loss: 0.6838 - acc: 0.5532\n",
      "Epoch 30/300\n",
      "1155/1155 [==============================] - 1s 765us/step - loss: 0.6798 - acc: 0.5749\n",
      "Epoch 31/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.6724 - acc: 0.5619\n",
      "Epoch 32/300\n",
      "1155/1155 [==============================] - 1s 921us/step - loss: 0.6801 - acc: 0.5619\n",
      "Epoch 33/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.6818 - acc: 0.5610\n",
      "Epoch 34/300\n",
      "1155/1155 [==============================] - 1s 860us/step - loss: 0.6786 - acc: 0.5732\n",
      "Epoch 35/300\n",
      "1155/1155 [==============================] - 1s 802us/step - loss: 0.6709 - acc: 0.5732\n",
      "Epoch 36/300\n",
      "1155/1155 [==============================] - 1s 805us/step - loss: 0.6686 - acc: 0.5775\n",
      "Epoch 37/300\n",
      "1155/1155 [==============================] - 1s 812us/step - loss: 0.6707 - acc: 0.5766\n",
      "Epoch 38/300\n",
      "1155/1155 [==============================] - 1s 890us/step - loss: 0.6676 - acc: 0.5818\n",
      "Epoch 39/300\n",
      "1155/1155 [==============================] - 1s 789us/step - loss: 0.6644 - acc: 0.5792\n",
      "Epoch 40/300\n",
      "1155/1155 [==============================] - 1s 758us/step - loss: 0.6540 - acc: 0.5991\n",
      "Epoch 41/300\n",
      "1155/1155 [==============================] - 1s 763us/step - loss: 0.6577 - acc: 0.6026\n",
      "Epoch 42/300\n",
      "1155/1155 [==============================] - 1s 780us/step - loss: 0.6594 - acc: 0.5870\n",
      "Epoch 43/300\n",
      "1155/1155 [==============================] - 1s 765us/step - loss: 0.6481 - acc: 0.6061\n",
      "Epoch 44/300\n",
      "1155/1155 [==============================] - 1s 847us/step - loss: 0.6440 - acc: 0.6069\n",
      "Epoch 45/300\n",
      "1155/1155 [==============================] - 1s 987us/step - loss: 0.6370 - acc: 0.6165\n",
      "Epoch 46/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.6322 - acc: 0.6173\n",
      "Epoch 47/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.6444 - acc: 0.6294\n",
      "Epoch 48/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.6272 - acc: 0.6381\n",
      "Epoch 49/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.6207 - acc: 0.6554\n",
      "Epoch 50/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.6100 - acc: 0.6667\n",
      "Epoch 51/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.6234 - acc: 0.6407\n",
      "Epoch 52/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.5896 - acc: 0.6623\n",
      "Epoch 53/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.5815 - acc: 0.6675\n",
      "Epoch 54/300\n",
      "1155/1155 [==============================] - 1s 931us/step - loss: 0.5850 - acc: 0.6848\n",
      "Epoch 55/300\n",
      "1155/1155 [==============================] - 1s 1000us/step - loss: 0.5806 - acc: 0.6831\n",
      "Epoch 56/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.5597 - acc: 0.6978\n",
      "Epoch 57/300\n",
      "1155/1155 [==============================] - 1s 943us/step - loss: 0.5689 - acc: 0.6684\n",
      "Epoch 58/300\n",
      "1155/1155 [==============================] - 1s 918us/step - loss: 0.5463 - acc: 0.7039\n",
      "Epoch 59/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.5414 - acc: 0.6987\n",
      "Epoch 60/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.5487 - acc: 0.7056\n",
      "Epoch 61/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.5232 - acc: 0.7247\n",
      "Epoch 62/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.5342 - acc: 0.7065\n",
      "Epoch 63/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.4953 - acc: 0.7481\n",
      "Epoch 64/300\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 0.5187 - acc: 0.7325\n",
      "Epoch 65/300\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 0.4893 - acc: 0.7455\n",
      "Epoch 66/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.4719 - acc: 0.7645\n",
      "Epoch 67/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.4607 - acc: 0.7610\n",
      "Epoch 68/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.4603 - acc: 0.7628\n",
      "Epoch 69/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.4666 - acc: 0.7628\n",
      "Epoch 70/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.4506 - acc: 0.7861\n",
      "Epoch 71/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.4556 - acc: 0.7697\n",
      "Epoch 72/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.4130 - acc: 0.8156\n",
      "Epoch 73/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.4097 - acc: 0.8104\n",
      "Epoch 74/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.4235 - acc: 0.8009\n",
      "Epoch 75/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.4014 - acc: 0.8087\n",
      "Epoch 76/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.3956 - acc: 0.8069\n",
      "Epoch 77/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.4038 - acc: 0.8069\n",
      "Epoch 78/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.3842 - acc: 0.8199\n",
      "Epoch 79/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.3633 - acc: 0.8312\n",
      "Epoch 80/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.3905 - acc: 0.8165\n",
      "Epoch 81/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.3485 - acc: 0.8424\n",
      "Epoch 82/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.3537 - acc: 0.8407\n",
      "Epoch 83/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.3647 - acc: 0.8303\n",
      "Epoch 84/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.3514 - acc: 0.8390\n",
      "Epoch 85/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.3652 - acc: 0.8390\n",
      "Epoch 86/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.3351 - acc: 0.8502\n",
      "Epoch 87/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.3335 - acc: 0.8442\n",
      "Epoch 88/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.3002 - acc: 0.8589\n",
      "Epoch 89/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.3011 - acc: 0.8623\n",
      "Epoch 90/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2962 - acc: 0.8684\n",
      "Epoch 91/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2959 - acc: 0.8597\n",
      "Epoch 92/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2688 - acc: 0.8840\n",
      "Epoch 93/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2717 - acc: 0.8727\n",
      "Epoch 94/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2925 - acc: 0.8649\n",
      "Epoch 95/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2917 - acc: 0.8797\n",
      "Epoch 96/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2665 - acc: 0.9004\n",
      "Epoch 97/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.2566 - acc: 0.8883\n",
      "Epoch 98/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2593 - acc: 0.8944\n",
      "Epoch 99/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2490 - acc: 0.8978\n",
      "Epoch 100/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2733 - acc: 0.8848\n",
      "Epoch 101/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.2517 - acc: 0.8883\n",
      "Epoch 102/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.2782 - acc: 0.8831\n",
      "Epoch 103/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.2342 - acc: 0.8935\n",
      "Epoch 104/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.2128 - acc: 0.9039\n",
      "Epoch 105/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.2400 - acc: 0.8952\n",
      "Epoch 106/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.2763 - acc: 0.8857\n",
      "Epoch 107/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.2166 - acc: 0.9143\n",
      "Epoch 108/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2873 - acc: 0.8779\n",
      "Epoch 109/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2335 - acc: 0.8987\n",
      "Epoch 110/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2533 - acc: 0.9004\n",
      "Epoch 111/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.2122 - acc: 0.9065\n",
      "Epoch 112/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.2483 - acc: 0.8866\n",
      "Epoch 113/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.2382 - acc: 0.9100\n",
      "Epoch 114/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1945 - acc: 0.9273\n",
      "Epoch 115/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.2304 - acc: 0.9091\n",
      "Epoch 116/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1781 - acc: 0.9212\n",
      "Epoch 117/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2090 - acc: 0.9117\n",
      "Epoch 118/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.2079 - acc: 0.9160\n",
      "Epoch 119/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1928 - acc: 0.9212\n",
      "Epoch 120/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.2020 - acc: 0.9091\n",
      "Epoch 121/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1959 - acc: 0.9134\n",
      "Epoch 122/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1836 - acc: 0.9212\n",
      "Epoch 123/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2204 - acc: 0.9074\n",
      "Epoch 124/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1799 - acc: 0.9247\n",
      "Epoch 125/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1717 - acc: 0.9281\n",
      "Epoch 126/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.2315 - acc: 0.9039\n",
      "Epoch 127/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1845 - acc: 0.9273\n",
      "Epoch 128/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1772 - acc: 0.9290\n",
      "Epoch 129/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1879 - acc: 0.9273\n",
      "Epoch 130/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1890 - acc: 0.9195\n",
      "Epoch 131/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1739 - acc: 0.9195\n",
      "Epoch 132/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1816 - acc: 0.9281\n",
      "Epoch 133/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1936 - acc: 0.9264\n",
      "Epoch 134/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1814 - acc: 0.9333\n",
      "Epoch 135/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1990 - acc: 0.9039\n",
      "Epoch 136/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1578 - acc: 0.9342\n",
      "Epoch 137/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1660 - acc: 0.9307\n",
      "Epoch 138/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1695 - acc: 0.9281\n",
      "Epoch 139/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1280 - acc: 0.9463\n",
      "Epoch 140/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1765 - acc: 0.9325\n",
      "Epoch 141/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1432 - acc: 0.9325\n",
      "Epoch 142/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1674 - acc: 0.9325\n",
      "Epoch 143/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1546 - acc: 0.9411\n",
      "Epoch 144/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1728 - acc: 0.9238\n",
      "Epoch 145/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1253 - acc: 0.9498\n",
      "Epoch 146/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1727 - acc: 0.9203\n",
      "Epoch 147/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1818 - acc: 0.9273\n",
      "Epoch 148/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1504 - acc: 0.9472\n",
      "Epoch 149/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1412 - acc: 0.9455\n",
      "Epoch 150/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1570 - acc: 0.9351\n",
      "Epoch 151/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1385 - acc: 0.9403\n",
      "Epoch 152/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1734 - acc: 0.9351\n",
      "Epoch 153/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1600 - acc: 0.9333\n",
      "Epoch 154/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1544 - acc: 0.9307\n",
      "Epoch 155/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1312 - acc: 0.9429\n",
      "Epoch 156/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1533 - acc: 0.9394\n",
      "Epoch 157/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1276 - acc: 0.9489\n",
      "Epoch 158/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1368 - acc: 0.9515\n",
      "Epoch 159/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1820 - acc: 0.9273\n",
      "Epoch 160/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1506 - acc: 0.9377\n",
      "Epoch 161/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1166 - acc: 0.9515\n",
      "Epoch 162/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1512 - acc: 0.9351\n",
      "Epoch 163/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1373 - acc: 0.9403\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1354 - acc: 0.9420\n",
      "Epoch 165/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1197 - acc: 0.9584A: 1s - l\n",
      "Epoch 166/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1573 - acc: 0.9394\n",
      "Epoch 167/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1190 - acc: 0.9524\n",
      "Epoch 168/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1877 - acc: 0.9316\n",
      "Epoch 169/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1443 - acc: 0.9498\n",
      "Epoch 170/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1425 - acc: 0.9429\n",
      "Epoch 171/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1404 - acc: 0.9463\n",
      "Epoch 172/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1281 - acc: 0.9472\n",
      "Epoch 173/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1211 - acc: 0.9498\n",
      "Epoch 174/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1699 - acc: 0.9273\n",
      "Epoch 175/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1087 - acc: 0.9567\n",
      "Epoch 176/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1359 - acc: 0.9403\n",
      "Epoch 177/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1278 - acc: 0.9550\n",
      "Epoch 178/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1213 - acc: 0.9515\n",
      "Epoch 179/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1265 - acc: 0.9463\n",
      "Epoch 180/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1130 - acc: 0.9576\n",
      "Epoch 181/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1391 - acc: 0.9446\n",
      "Epoch 182/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1120 - acc: 0.9567\n",
      "Epoch 183/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1406 - acc: 0.9498\n",
      "Epoch 184/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1230 - acc: 0.9524\n",
      "Epoch 185/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1045 - acc: 0.9576\n",
      "Epoch 186/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1512 - acc: 0.9437\n",
      "Epoch 187/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1187 - acc: 0.9481\n",
      "Epoch 188/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1012 - acc: 0.9576\n",
      "Epoch 189/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0982 - acc: 0.9610\n",
      "Epoch 190/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1149 - acc: 0.9515\n",
      "Epoch 191/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1362 - acc: 0.9524\n",
      "Epoch 192/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1039 - acc: 0.9593\n",
      "Epoch 193/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0995 - acc: 0.9610\n",
      "Epoch 194/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1065 - acc: 0.9610\n",
      "Epoch 195/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1132 - acc: 0.9541\n",
      "Epoch 196/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1214 - acc: 0.9628\n",
      "Epoch 197/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1205 - acc: 0.9524\n",
      "Epoch 198/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1170 - acc: 0.9515\n",
      "Epoch 199/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1050 - acc: 0.9541\n",
      "Epoch 200/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1409 - acc: 0.9515A: 1s - l\n",
      "Epoch 201/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1094 - acc: 0.9524\n",
      "Epoch 202/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1018 - acc: 0.9602\n",
      "Epoch 203/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1031 - acc: 0.9654\n",
      "Epoch 204/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0877 - acc: 0.9732\n",
      "Epoch 205/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1167 - acc: 0.9550\n",
      "Epoch 206/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1065 - acc: 0.9593\n",
      "Epoch 207/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0904 - acc: 0.9645\n",
      "Epoch 208/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1130 - acc: 0.9567\n",
      "Epoch 209/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1507 - acc: 0.9368\n",
      "Epoch 210/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1174 - acc: 0.9550\n",
      "Epoch 211/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1195 - acc: 0.9506\n",
      "Epoch 212/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1080 - acc: 0.9584\n",
      "Epoch 213/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0909 - acc: 0.9576\n",
      "Epoch 214/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0831 - acc: 0.9671\n",
      "Epoch 215/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0919 - acc: 0.9654\n",
      "Epoch 216/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1175 - acc: 0.9567\n",
      "Epoch 217/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1497 - acc: 0.9463\n",
      "Epoch 218/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0918 - acc: 0.9636\n",
      "Epoch 219/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1104 - acc: 0.9489\n",
      "Epoch 220/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1140 - acc: 0.9524\n",
      "Epoch 221/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0971 - acc: 0.9610\n",
      "Epoch 222/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1090 - acc: 0.9550\n",
      "Epoch 223/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1065 - acc: 0.9593\n",
      "Epoch 224/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1042 - acc: 0.9610\n",
      "Epoch 225/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0883 - acc: 0.9680\n",
      "Epoch 226/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.0828 - acc: 0.9636\n",
      "Epoch 227/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1086 - acc: 0.9498\n",
      "Epoch 228/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.1185 - acc: 0.9593\n",
      "Epoch 229/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0905 - acc: 0.9628\n",
      "Epoch 230/300\n",
      "1155/1155 [==============================] - ETA: 0s - loss: 0.1145 - acc: 0.954 - 1s 1ms/step - loss: 0.1147 - acc: 0.9541\n",
      "Epoch 231/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1377 - acc: 0.9463\n",
      "Epoch 232/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0926 - acc: 0.9576\n",
      "Epoch 233/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1013 - acc: 0.9645\n",
      "Epoch 234/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1052 - acc: 0.9576\n",
      "Epoch 235/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0905 - acc: 0.9688\n",
      "Epoch 236/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1027 - acc: 0.9645\n",
      "Epoch 237/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0836 - acc: 0.9645\n",
      "Epoch 238/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1082 - acc: 0.9558\n",
      "Epoch 239/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1158 - acc: 0.9515\n",
      "Epoch 240/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0921 - acc: 0.9654\n",
      "Epoch 241/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0775 - acc: 0.9697\n",
      "Epoch 242/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1418 - acc: 0.9515\n",
      "Epoch 243/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1006 - acc: 0.9602\n",
      "Epoch 244/300\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 0.0742 - acc: 0.9740\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1024 - acc: 0.9619\n",
      "Epoch 246/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1214 - acc: 0.9550\n",
      "Epoch 247/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0980 - acc: 0.9593\n",
      "Epoch 248/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1363 - acc: 0.9541\n",
      "Epoch 249/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0859 - acc: 0.9680\n",
      "Epoch 250/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0672 - acc: 0.9706\n",
      "Epoch 251/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0669 - acc: 0.9758\n",
      "Epoch 252/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1020 - acc: 0.9654\n",
      "Epoch 253/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0777 - acc: 0.9714\n",
      "Epoch 254/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0901 - acc: 0.9645\n",
      "Epoch 255/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0672 - acc: 0.9732\n",
      "Epoch 256/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1037 - acc: 0.9550\n",
      "Epoch 257/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0929 - acc: 0.9636\n",
      "Epoch 258/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1042 - acc: 0.9610\n",
      "Epoch 259/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0620 - acc: 0.9732\n",
      "Epoch 260/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0746 - acc: 0.9723\n",
      "Epoch 261/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0675 - acc: 0.9706\n",
      "Epoch 262/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1172 - acc: 0.9524\n",
      "Epoch 263/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0823 - acc: 0.9654\n",
      "Epoch 264/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0828 - acc: 0.9706\n",
      "Epoch 265/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1103 - acc: 0.9584\n",
      "Epoch 266/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0978 - acc: 0.9550\n",
      "Epoch 267/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0871 - acc: 0.9662\n",
      "Epoch 268/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0926 - acc: 0.9636\n",
      "Epoch 269/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0893 - acc: 0.9671\n",
      "Epoch 270/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1194 - acc: 0.9524\n",
      "Epoch 271/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0893 - acc: 0.9671\n",
      "Epoch 272/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0731 - acc: 0.9706\n",
      "Epoch 273/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0806 - acc: 0.9688\n",
      "Epoch 274/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0652 - acc: 0.9784\n",
      "Epoch 275/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0792 - acc: 0.9680\n",
      "Epoch 276/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0698 - acc: 0.9740\n",
      "Epoch 277/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0860 - acc: 0.9706\n",
      "Epoch 278/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0970 - acc: 0.9636\n",
      "Epoch 279/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0870 - acc: 0.9654\n",
      "Epoch 280/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1652 - acc: 0.9506\n",
      "Epoch 281/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.1114 - acc: 0.9541\n",
      "Epoch 282/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0865 - acc: 0.9645\n",
      "Epoch 283/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0731 - acc: 0.9732\n",
      "Epoch 284/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0917 - acc: 0.9654\n",
      "Epoch 285/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0805 - acc: 0.9680\n",
      "Epoch 286/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0852 - acc: 0.9645\n",
      "Epoch 287/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0672 - acc: 0.9801\n",
      "Epoch 288/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0774 - acc: 0.9732\n",
      "Epoch 289/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0634 - acc: 0.9732\n",
      "Epoch 290/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0661 - acc: 0.9723\n",
      "Epoch 291/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0790 - acc: 0.9654\n",
      "Epoch 292/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0744 - acc: 0.9688\n",
      "Epoch 293/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0726 - acc: 0.9714\n",
      "Epoch 294/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0869 - acc: 0.9680\n",
      "Epoch 295/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0818 - acc: 0.9732\n",
      "Epoch 296/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0654 - acc: 0.9784\n",
      "Epoch 297/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0790 - acc: 0.9662\n",
      "Epoch 298/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0710 - acc: 0.9758\n",
      "Epoch 299/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0690 - acc: 0.9723\n",
      "Epoch 300/300\n",
      "1155/1155 [==============================] - 1s 1ms/step - loss: 0.0745 - acc: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9ff5040f98>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model, time for witchcraft\n",
    "model = model(X[0].shape)\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x = X_train, y = Y_train, epochs = 300, batch_size = 8,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s 828us/step\n",
      "\n",
      "Loss = 2.69343784795\n",
      "Acc = 0.509090909813\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(x = X_test, y = Y_test)\n",
    "print()\n",
    "print(\"Loss = \" + str(preds[0]))\n",
    "print(\"Acc = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9ff20e7ac8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEICAYAAABLdt/UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XecXHd57/HPM2Vn+6rsqlteyZLcZcsI44ZNMWBwAwIh\nwXBjh2Dg0kIguYSYdmmGS4ghlNiY0CEQwJgQwAVwjLvlbtmSLcuy1bWq27QzOzPP/eOcWY1WbcuZ\nsrPf9+s1L00583vOOTt65jfP+Z3fMXdHRERqR6zSKyAiItFSYhcRqTFK7CIiNUaJXUSkxiixi4jU\nGCV2EZEao8QuIlJjlNhFRGqMEruISI1JVCJoe3u7d3Z2ViK0iMiE9cADD2x3944jLVeRxN7Z2cmK\nFSsqEVpEZMIys+dGspxKMSIiNUaJXUSkxiixi4jUGCV2EZEao8QuIlJjlNhFRGqMEruISBVZvaWH\nZ7f3jauNioxjFxGRg3vVNbcDsO7qC8fchnrsIiI1RoldRKQK7ekfHPN7ldhFRKrQszvGXmePLLGb\n2RQz+5mZrTKzJ83szKjaFhGZbLK5/JjfG+XB0y8Dv3P3N5hZHdAYYdsiIpPKYM7H/N5IEruZtQLn\nApcDuHsGyETRtojIZDQ4jh57VKWYhUAX8G0ze8jMrjezpuIFzOxKM1thZiu6uroiCisiUpuy+con\n9gRwGvANd18G9AEfLl7A3a9z9+Xuvryj44jzxIuITGrjKcVEldg3ABvc/d7w8c8IEr2IiIxBxUsx\n7r4FWG9mx4ZPvRx4Ioq2RUQmo2ylD56G3gv8MBwRsxa4IsK2RURqnvu+ZD6eHntkid3dHwaWR9We\niMhkU1xXr4Yau4iIjFMuvy+ZV8OoGBERGafBomSuHruISA3I5qKpsSuxi4hUieL5YcYzV4wSu4hI\nlcjmozl4qisoiYhUiUOVYjbt3kvPQHbE7Sixi4hUieKDp8W997Ou/sOo2lEpRkSkShT32DNZ1dhF\nRCa87H49diV2EZEJ77bV+6Y0H89cMUrsIiJVIJ3N8f9uWj30OKPhjiIiE9uxV/1uv8fqsYuITGDF\nszoWqMYuIjKBFU/+VaBRMSIiE9jwvN7eXEdaiV1EZOLKDyvFdE5vIj2oxC4iMmEV5/VXnTiT5voE\nA9kcAPmDlGmOJLLEbmbrzOwxM3vYzFZE1a6ISK0r7rG//PiZ1CfiDAwGiT07hsQe9VwxL3X37RG3\nKSJS04oTeyJm1CdjDISlmIMdWD0SlWJERCqseGRjPGakEnF601n+9HTXmIY9RpnYHbjZzB4wsysj\nbFdEpKYV99jjYY99Z1+Gt37rPu5cM/oiSJSlmLPdfZOZzQBuMbNV7n574cUw2V8JMH/+/AjDiohM\nbMNLMbGYDT1es6131O1F1mN3903hv9uAG4DTh71+nbsvd/flHR0dUYUVEZnwisvoMTPiti+xb+/N\njLq9SBK7mTWZWUvhPvBK4PEo2hYRqXXFUwok4ka8qMe+u3/0iT2qUsxM4AYLvmUSwI/c/XeHf4uI\niADk9quxx/YrxezeOzjq9iJJ7O6+FjglirZERCab4lJM3IyivM6Dz+0adXsa7igiUmHFZ5fGY/vX\n2LtHcRHrAiV2EZEKK55SoC6xfylmLJTYRUQqrHi444yW1H49doCW+tFVzZXYRUQqrDixtzenDuix\nt9YnR9WeEruISIUVEvvpndNoqIsTG9Zjr0uMLlUrsYuIVFjh2OlfndUJQHxYZk6MsuauxC4iUmGF\nHnshfw/vsSfiMX789jNG3J4Su4hIhRUmcAxP8jwgsSfjxpnHTB9xe0rsIiIVNrzHHh9WelEpRkRk\ngikMiin01AtXTypIDC+6H4ESu4hIhRXmiomFGXlH3/4TfyXj6rGLiEwo+0oxQQIfXooZzI7u8nhK\n7CIiFebDEvvw65zet27nqNpTYhcRqbD8sBp7Jjv665wWU2IXEamwQg+9MMpxeI99tJTYRUQqrDBt\nb6G2ns2rxy4iMqEVRsUUxqsP5vbvsV8eTjUwUkrsIiIVls0XhjsGib2tYf/ZHEdz1ilEd81TzCwO\nrAA2uvtFUbUrIlLrhkoxYZH9Q688lgXtTdy2ehu3PrmN0V52I8oe+/uBJyNsT0RkUsgOq7E31MV5\nyxlHH3BG6khFktjNbB5wIXB9FO2JiEwmww+eFhQq7aPM65H12K8B/gE45KFcM7vSzFaY2Yqurq6I\nwoqITHzDD54WDD8jdaTGndjN7CJgm7s/cLjl3P06d1/u7ss7OjrGG1ZEpGbkhh08LRgazl6BHvvZ\nwCVmtg74D+BlZvaDCNoVEZkUCol9eI99+FQDIzXuxO7u/+ju89y9E/gL4A/u/pbxtisiMlkMDXe0\n4Yk9+LeSo2JERGQMCgdPE8Om533neccAcPLctlG1F9k4dgB3vw24Lco2RURqXXbYOPaCcxa3s+7q\nC0fdnnrsIiIVVhj9Mny441gpsYuIVFg2p8QuIlJT1GMXEakxw6cUGC8ldhGRCtuzdxAY/Xj1Q1Fi\nFxGpsF8/ugk48ASlsYp0uKOIiIxeSyrJzNY8iXg0fW312EVEKqw/k+X0BaO7mMbhKLGLiFRYz0CW\nlvroCihK7CIiFeTuSuwiIrWkeyBLJpenozkVWZtK7CIiFbRhVz8A7UrsIiK14Z61OwE4dlZLZG0q\nsYuIVFB3eHLSsTOV2EVEakImlycZtwMuizceSuwiIhWUyeapi+jEpAIldhGRCspk89QlqjCxm1m9\nmd1nZo+Y2Uoz+2QU7YqI1LpSJPaoRsSngZe5e6+ZJYE7zOy37n5PRO2LiNSkTK5KE7u7O9AbPkyG\nN4+ibRGRWlbVNXYzi5vZw8A24BZ3vzeqtkVEatWTW7qpS8QjbTOyxO7uOXc/FZgHnG5mJxW/bmZX\nmtkKM1vR1dUVVVgRkQnr/nU7WdvVx5ObuyNtN/JRMe6+G7gNuGDY89e5+3J3X97R0RF1WBGRCefp\nrUEFu6MluukEILpRMR1mNiW83wCcD6yKom0RkVq1qz8DwG/e9+JI241qVMxs4LtmFif4svipu/86\norZFRGpSbzpLIma0N9dF2m5Uo2IeBZZF0ZaIyGTRl87SlEpgEV3EukBnnoqIVEhvOktzKvpLTyux\ni4hUSNBjj3aoIyixi4hUTF86px67iEgt6Q1r7FFTYhcRqZA+1dhFRGpLn3rsIiK1RaNiRERqiLvT\nl8lpVIyISK1IZ/Pk8q5SjIhIrehNZwFUihERqQV79g6y/NO3AtBUp8QuIjLh3bt2x9D91oZk5O0r\nsYuIlNnewdzQ/dlt9ZG3r8QuIlJmf1y1bej+UVMbI28/+uKOiIgc0pptvfzy4U0APP2ZV5OM+ELW\noB67iEhZ9WeyQ/dLkdRBiV1EpKwGc3kATjlqSsliqBQjIlImdz+zg75w/PpVFx5fsjiRJHYzOwr4\nHjALyAPXufuXo2hbRGSi27Crn3f/6CEeWb+baU3B9U0bktFPJVAQVY89C3zQ3R80sxbgATO7xd2f\niKh9EZEJ6yf3r+eR9bsB2NmXAaChrnSJPZIau7tvdvcHw/s9wJPA3CjaFhGZ6Lb3Zg54rpQ99sgP\nnppZJ7AMuHfY81ea2QozW9HV1RV1WBGRqtXVkz7gucZq77EXmFkz8HPgb929u/g1d7/O3Ze7+/KO\njo4ow4qIVLXtvQcm9vqJ0GM3syRBUv+hu/8iqnZFRCa67b1pZrXumzogZpBKlG60eSQtm5kB3wKe\ndPcvRdGmiEgtcHe6etJcfMpszlsSVCsaknGCtFkaUX1lnA28FXiZmT0c3l4TUdsiIhNWbzpLOpun\nvTk1dLWkhhJM1Vssktbd/Q6gdF8/IiITVGFETEdLioZkkHLbGkqb2DWlgIhICRUOnLY3p2hvDk5O\nOmFOW0ljKrGLiJTQ9p59iX1WOPd63r2kMZXYRURK6OcPbgCgvaWO6c0pAPZmcod7y7hpEjARkRK4\nc812Ymbc+mRwUY3pTSmaw4OnuXxpe+xK7CIiEXN3Lrt+v5PviceMRCwokpQ6sasUIyISsZ50dr/H\nl5/VCUAiFgwezObzJY2vHruISIQ279nLdbev3e+53jDRzwjPPj15bmlHxSixi4hE6Is3PTV0wLTg\nrGOmA7BoRjO/fu85HDurpaTroMQuIhKhLd17D3ju9afNG7p/Uol766Aau4hIpLr3BmWXK87uBOD0\nzmllXwf12EVEItQ9MMglp8zh4xefyEVL57B4ZnPZ10GJXUQkQt17B2lrSALwgqOnVmQdVIoREYmI\nu9M9kKW1xJN8HYkSu4hIRPozOXJ5p7U+WdH1UGIXERmBrp40mezhTyzqHhgEoLVBiV1EpKqlszle\n+Jlb+diNjx92uU27g6GObUrsIiLV7ZltfQD8ftW2wy53/Z+epakuzrL5U8qxWocU1TVP/93MtpnZ\n4b/OREQmoKt++RgQlGPe+q17D7nciud28aoTZzG7raFcq3ZQUfXYvwNcEFFbIiJV5cHndw/d/9PT\n2xkYPHA+9W3dA3T1pMtyZumRRJLY3f12YGcUbYmIVIPugUEGBnPc9cz2A17bsmdgv8dfunk1p3/2\n9wCcOKe1LOt3ODpBSURkmO6BQZZ+4maWzmvj0Q17AGhJJYam4/3CTav4+mUvAIKx61/5w5qh955Q\nBYm9bAdPzexKM1thZiu6urrKFVZEZNQ+9svgcGEhqb/jvIX8xzvOGHr9ttVdQ0Mb/+WWp4aeP2dR\nOy0VHsMOZUzs7n6duy939+UdHR3lCisiMmoDg/uPVz9vcQcnzmlj3dUX8u0rXkh/JseXbn6K+9ft\n5P51uwD43l+fzr+99QWVWN0DqBQjIjLM9t40p8xrY/XWHgYG8yybv2/Ol87pTQB85651fOeudQAs\nmz+Fc5dUT4c1ksRuZj8GXgK0m9kG4OPu/q0o2hYRKbfNewZ40YJpfOeK00ln8zTUxYdea2+uO2D5\n1Vt6yrl6RxRJYnf3v4yiHRGRSsvlnS3dA8yeUs/UpgOTeGPdgWnzExefWI5VGzGdeSoiUmRbzwC5\nvDNnysFPMoqHF6QudvqC8l9M43BUYxcRKVKY72XOCM4endma4ujpTXS2N5V6tUZFiV1EJOTu/Nk3\n7gY4ZI+92L0fOb/UqzQmKsWIiITWbOsduj9/WmMF12R81GMXEQn91yObAOhoSe03Ema415w8a0Sl\nmkpRYhcRCa3p6mVWaz33fOTlh12uMJ1AtVIpRkRq0p7+QfJ5H9179g4yd2r19sRHSoldRGrOE5u6\nOeX/3sz1d6w97HJ96Sx/erqLwVyeNdt6Wb2lt+JXP4qCSjEiUlP++9HNvPtHDwJwx5odnLmwnenN\ndQcd5XLFt+/nvnX7zzg+dwSjYaqdEruI1JQ7i+ZPv/2pLm5/KphN9rfvfzHHz24lm8uTiAfFiuFJ\nHeCCk2aVZ0VLSKUYEakpyYOcGQrw0xXr+e1jm1n0T7/l0q/egbtz0dLZ+y3znpcuqrqzSMdCiV1E\nakYmm+e7dz/HKUcdeDHpb9+5jnf9MCjRPLJhDw+t303e9x1c/fCrj+NDrzqWZHzip8WJvwUiMund\n+PBGXvCpW/jZAxsAOG9xO194w9Kh1195wswD3vP6r9/F6i09nDy3jZs/cC5XnN1ZrtUtOdXYRWTC\n++G9z7OjL8M//fIxknHjyvOOIZdzNp8/wFvOmE9zfYKbV27ls795kmvf+gIu+eqdADzT1QfAkpkt\nlVz9yCmxi8iEN5gLrnjkDoM5pzkVpLb3n794aJmLT5nDxafMAeDBj76C0z51CwBvWn5Umde29FSK\nEZEJ7YaHNvDQ87uHHr/jvIVHfM+0onnW3/3SRSVZr0pSYheRCSmXdwZzeT73m1X7Pf/hC44b0fvb\nm1MAzGhNRb5ulRZZKcbMLgC+DMSB69396qjaFhEZ7tKv3cHjG7sB+MD5S1g2fwp1iRhmBx/uONwN\n//ssHnx+F/XJQ0/2NVFFdc3TOPA14BXABuB+M/uVuz8RRfsiIsUeXr97KKnXxWNcflYnbY2jmwrg\nqGmNHDWBp+Y9nKh67KcDa9x9LYCZ/QdwKaDELiKR+vkDG/jgfz5CPGb813vO4ahpDbTUT/z5XaIU\nVY19LrC+6PGG8DkRkcg8vnEPH/zPRwD44CuXcMKcViX1g4iqx36wotZ+82Wa2ZXAlQDz58+PKKyI\nTAbZXJ4f3/c8H71xJRDUx5fNn1rhtapeUSX2DUDxYNB5wKbiBdz9OuA6gOXLl49ukmQRqSmPb9zD\nZ/77SV60cBpXnL2A1vrEQQ96PvDcTtoa6vinGx7j3meDCbs+demJSupHEFVivx9YbGYLgI3AXwBv\njqhtEalSu/szPL+zn6XzDpyb5WDueHo7b//eCvYO5gC4e+0Orrn1aV63bC5XXXg808MhiF+65Sm+\n8vunh95nFszlcvlZnTU5iiVqkSR2d8+a2XuAmwiGO/67u6+Mom0RqV5vuvYeVm/tYdWnLjhowv3j\n6m3c/lQXl71oPnc/s2OolLJ4RjOfvORE3nz9vQDc8NBGbnhoI29afhSbuweGpto9c+F05k1t4Iqz\nF3DCnNbybdgEZ+7lr4osX77cV6xYUfa4IjJ+mWyeXzy4getuX8va7cFcKx+96AQuP6uTZ7p6eWpr\nD20NSa79n7XcsWb7fu+dO6WBT7/uJF567AwAtnUPsKMvw00rt3DNrft66KcvmMYX33AK86fX5nDE\nsTKzB9x9+RGXU2IXkZHqHhjkEzeu5BcPbQTg3CUdQ73rg7lw6WyWzm2jL5PjpDmtnH/8TGKHmC/9\nV49s4mM3Ps6HXnksbz59/iGXm8xGmtg1CZhIBdy0cgvv/uGDLJ3Xxk/ecSYAz27vY1FHMw7ELDhl\nPlHCucH70ll+fN/z3LN2By9aMJ14zDCDP67uYs/eQY6f1cKGXXt5dnsfsRhs7U6TyQaTbc2f1shP\n3nEGs9sauO/Znfz5tXcPtfu5159M3IzTjp7KohnNI16fS06ZwyXhJF0yPlXbY3d37lm7k6/ftoYH\nntvF9OY6muoSXHbG0TSn4hw7s5XfPLaZe9buYP60RrJ5Z1pTHbm8096c4rSjp5CMx6hLxIib0Tm9\nadRnpolEbXd/hluf3MaHwrHYh1KXiJHJ5pnZmqI+GWd2Wz2XnjqXma0pOprr6WhJETPI5PLEzHhi\nUzePbtzD7v4MHc0pGuri1CVi1MVj5NzpT+fY2j3A09t6iceMTbuDhJ0OE/VwM1tTpLN5pjQkmdVW\nz/TmFPOmNDCtqY5jOpp56XEziBf1qB94bif9mRxnHdO+3/MSraouxUzvPN4/+PVfsOyoKbzihJkH\n9Eoe3bCbj/9q5dCMbYWroTyyfvcBbc2b2kDPQJa8O+4Qjxl79g4esFwiZlxw0qzwP4Qxd0oDne2N\nNNUlaGtMkss7i2e0UJfQvGgT0WAuT9ysYj/fe9NZ6hMxEvEY2XAK2eLP9T/fvJqbV25l9daeoed+\n/PYz+OebV7PiuV0smtFMOpsjGYvR0ZJi7tQGOlpSPLe9n0TcuP2pLroHskdcj6a6OH2Z3CFf75ze\nSHN9gnwejpvVwrlLOmhrTNLRnGJ6cx29A1k625tq4ipCtaiqE3tq9mKf/VfXAEHPpK0hSVNdnO6B\nLK31Cdbt6Cdm8KYXzufPl89j2fypuDs/uOc5WuqTLJrRzEPrd9M5vZFzFrUfMP51e2+axzbuYfPu\nAWa2phjMOV/43aqhAz2H0pxKcOysFpbOa+O0+VM579gOsjnn4fW76BnI0lKfYMnMFua0NRCLGfm8\n85271rF6Sw8XnDSLma31bO9N01gXp7EuQXtzHTNa60u2H2vd01t7uOfZncxpq+fcJR1DySaTzfPo\nht2ks3n+uGobNz6yia6eNHXxGKlEjFlt9bQ3p9i4ey+7+jN0tKRY2N7MtKYki2e0sGhmMzEzegYG\nScZjrNy4h9Vbe9jSnSYVjxGPGUvntbGrP0Ms/LIYzOYZyOZJxo30YJ7+TJaBwTwD2Rw7eoMhfzGD\nRCxGJpcnHjPiMRt6rjedJWZwxdkLeGHnVI6d1cqC9iYy2TyJ2JG/kNLZHNu602zvTbN5zwBb9gwE\nv0ZjRjaXp7UhyUuOnUFbQ5J0Nkc6mycT3hIxoyH8TKo3PbFVdWI/Yeky/+Utt3Pvszt5ZlsvPQNZ\ntvUM0JCMk0rGmd5Ux9vOWRDpBD0DgzluW72NGa31LJjexGA+z6rNPXQPDIbTfzqf+NVKetNH7hUB\nLOxooqsnTc8RelGJmLGwo4nGugSDuTyz2+qpS8RYOm8Ki2c0c9Yx7TTUxenPZFnb1ceJc1qHvqgG\nBnOYQTIWw4GVm/awZc8A23sz9KYHaW9OsWRmC1MakzSnghM80tkcHc2pEc9wdyj5vLN3MEd/Jsfu\n/gx79g6yflc/a7v6WDQjSIxb9gzgONObgp/+86c10lqfpL2ljsa6/Q/fuPsh1ymXdwYGc+zsy7C1\ne4D1u/pZubGbXz68ie296aHlOlpStNQn2LBr71Ctt+CipbNpqU/y8Prd7M1kaQ/LEW0NSX796OYj\nbu/8aY00hsvv2TvIqi09TG1MEo8ZmWx+qLSRyzn1dXGa6hLUJ2PUJ+O0NiRZ2N5EbzpLKhGnsS5O\nOpsjmwv+b2VyedqbU/zNixeQSmgMtoxdVSf2ah0VMxjWK3f1Z1ixbifX3Po0y+ZP4eKlc2ipTzKQ\nzbFqSw9Pbelh854BZrSmOPWoKZw0p43ndvSxtXuA42e3ksnl6UvnWL+zn+29ae55diepRIzuvYPk\n3Xlqa+9+cV+8uJ0Hn9tFXyZHcyrB1KYkrfVJNu7ey+7+A8tKR5JKxOic3kQyYWRzTi7v5Dz8t+iW\ndyebdwyY2lhHOpsPk3nQGx2Po6Y1kErE2ZvJkc7m2NU/SHMqQSoRI++QzecZzOYZzDmZ3IGx6hIx\nTp03hcvOmM/NT2xly54BpjfVDZXKzlg4nWTceNlxM+loOfx82uu29/FMVy9HT2/EHbp60+zN5JjR\nUs9gPs/iGc0HzDcymMurHCFVR4m9iq3Z1kt/Jsv963bx2d88yZKZLRw/q4UZrfV09aTZ2ZfGLDhW\nMG9qA/OnNbI3k+OYGc0sbG9ienOKjuYUj2/aw46+DAOZHD3pLO5OMh7j+Z39PNPVS9yMRLxQErCh\nn/yF52MWvJZ3Z1ffIKlEjIa6OE2pBA3JeFhSCn7CtzYkmdqY5LjZrWzZM0Amm2dWWz2JuLGrL0PP\nQJYNu/ayuz/Diud2kc7myeaCnm4qEWNqYx196WyYxI26uJGMBzXpVCI21Fue2VbPUVMbOHq66rwi\nwymxTxDpbE4/z0VkREaa2NUlqjAldRGJmhK7iEiNUWIXEakxSuwiIjVGiV1EpMYosYuI1BgldhGR\nGlORcexm1gU8F1Fz7cD2Iy4VPcWt3biTaVsVd2LFPdrdO460UEUSe5TMbMVIBuwrruJWc0zFVdwo\nqRQjIlJjlNhFRGpMLST26xRXcWsgpuIqbmQmfI1dRET2Vws9dhERKaLEXmVsvJc+khHRfi497ePK\nmRCJ3cwuMbNjKr0eZTJ0Tbly/scwszeb2SnljltB2s+lp31cIVWd2M3sfDO7G/gWMLuMcV9rZp8q\nV7ww5gVmdhPwRTN7HYCX4QBIuI//BFwDLCtj3Nea2b+a2bRSxxoWV/u59DG1jyssceRFyiv8hm0C\nfgy0AFcBfwscDdxhZjF3H98FOQ8dOwb8NfBh4Ggzu9nd/1SKWGE8A5LAZ4Ezgc8D84A3mtnj7v50\nCePWA98FZgCfBi4FGsPX4+6eK2Hs1wGfIfj73mZmN5Tqb1oUU/u5hPtZ+7g8n+URc/eqvAFvKrr/\nbuCnZYp7HsEf6e3AbWWKeT6QCO+fSvAhTZQh7qVF998C3F2m7T0VmA78GXADMF/7uTb2s/ZxeT7L\nR7pVTSnGzN5nZleb2RsB3P0n4fNxYDew3swOfzn6scV9g5m9qOipu9y9x92/CTSZ2dvC5SLbV+G2\nftPM/gbA3W9196yZvQb4BbAE+KyZvSlcPpI6YVHct4dxbwyfjwPPAivN7KgoYg2L+1dm9oqipx53\n9x3u/nNgEHi9mdWVIK72c4n3s/ZxeT7Lo1bpbxbAgA8AdwJvAJ4ELgc6ipY5C1gVcdwZwP8Am4Bf\nArGi9SncfzWwEpgaYdzLgXuAC8L4HwEWha+dDiwJ778GuAnoLGHchUWvnwzcD7REuK1TgZ8Bm4FH\ngXj4fIx951CcDfweOG3450L7ubr3s/ZxeT7LY7lVvMfuwZa/FLjK3X9GkORPIfijFZa5C9hgZpdE\nGHcbcGMYZzPwjvAlc/e8mZm7/5bgi+ZKM2sp/JoYp5cDn3f33wEfBOqAy8J1us/dnwqXewLoArIR\nxDxU3LcUXnT3x4C9wF9EFA933wXcDBwPPAB8rOg1D/+9E3gYeLWZHWdmVxa/Pg7az5R8P2sfU5bP\n8qhVNLEXlTdWAC8GCP9YTwEnmtlx4XKtwCqCnzpRxv1Xgg/dzcCFZjY7TOox9u2b/wN8DngamBVB\nzIeAiwDcfQVBz2O2mZ097C2XExwA2jHWmCOIO6cQN/yJfDNQH8XP5aI2vufuu4GvE/xMPTrcx/Gi\ndbsG+EeC3teMYe8fbVzt5xLvZ+3j8nyWx6Osid3M2sJ/4wC+7+jxGqDFzE4OH/8P0AY0h8t1Exxh\nnxllXHcfdPcscBfBF8f7Cq+7e86CsfPfICjVnObu/zqKmLPCf2PDtvVOIGZm54aPHyf4xTAnXP5/\nmdnjwALgXe6+d5TbOqa4Ya9iBtA3lh7GQeIWejED4b/3A78lGEGAu+fC/xQzga8CfwBOdfdPF79/\nBHFPNLP6wuMy7ucxxY1gPw+PW/L9bGZnW9F5JGXcx2OKG8E+Hh63LJ/lSI2njjOSG8GXRyvwa+C7\nw14r1KkWAVcDf8e+I+q/At5ZtGx9hHGNoroXEAfOJTjYM49gQvxWgi+XJaOMu4ygzvbN4esT/jsN\n+BDwtaLt/wbwD+H9U4GzxrCfxxr374uWrYsw7tCxiqLn5hP0rk4EOgj+w8cZw0gCYClwB8FIhLll\n3M9jjTteH7HKAAAHWUlEQVTe/XyouCXbz8BpBD3fNEV14zLs47HGHe8+PlTckn6WS3EreY/dg2/Z\nHoI62Nyio+MJD8eXuvsagoMdiwjGkBPu3HVF7QxEGNfd3c0sZWYpD75xbyc4UPo48Cdgprvv8X11\nwsOywL8A3yP4Inl70WvFY+97wvbrCE7gSBIcmNkervfDHhxTGJEI4g79PHb3TIRx3YNeTIOZFX55\nPU+QmB4L12VquO+fH2ncIlcBP3P317n7xjBuvFT7OYK4Y9rPI4gb+X42s6SZXUswG+FXCA58vmQU\n2zrWz/J44471s3ykuKX+LEevHN8eBAccfghcTNATbyl67VMEZ5Z2AseFrz8AXMuwb8mI434S+D7h\nkXrgncA2ghMrkmOMdz1BHa7w+JjibQi39T/D7ZwNfIfgW/9awp5HjcX9JMGvoKXh478kuCTiF8ax\nj2NhnH8veu4VwBT2/dr7dNTbW+VxPxXlfiYogV4GNISPLwe+SdF49PBvG/W2VnPcj0f9WS7lLfoG\n4Qz2DXMqDANKAt8m+NnyZeC9BGeSngP8iHCIVNFOnlKmuMcUvf/84vUYbczwcSuwmuCI+Z3hB+F7\nBD/xlhxkW2OMYUjWBI57BrAggrgtBAezLyI4/nFTGPcfCToIpdreiRJ31Pv5YP9/il57G/BvhdcI\nykLD//+Me1snWNwxfZbLdYuuoaAH8d8EP5OuApqKXjsT+HJ4/0qCoU//BTQX/4EqFHfU3/JHiPk+\ngiFP5wIpgl8An2P/cfml2NZqjjvWntTh4n4EeBC4JHx8LsHw1TNLvL3VHDeyzzL7n8+xCNhKeD4H\n+x+finRbJ0DcMf/CLectyhp7E0FP4r3h/XOLXnueYNTLT4B/IPiArnH3XjigFlzuuGOZR+KQMd39\nK8BL3f12d08T9LCWA/1FMSPf1iqPO9a5Og73t/01QW+1MPHSCmALMFAUtxSfqWqOG9ln2QOFob/r\nwmXOK7xWFDPSbZ0AcUsy70zUxpXYw+FM55lZqwcHdK4DfkrwYXuRmc0JF51KcOR4C8EoincCx5rZ\n8bDfMKaqjTuKmHhwMkPBC4D1QOFAcam2dbLEnRu2+yjw98C7zayd4ASVkwkPoCnuuGIWhita2G5h\neGXhS8RKtK01FbeSRn1pvHAjZxHUnPLAMwTffO939+3hMmcDfw6scPfvh8+1F73eTDAcaWc1xx1l\nzPvd/QfhcymCMtAXCcbXftBHOLpGcUf+tw2f/ztgIbAY+IC7P6G4445Z/LeNe3BOx/eBZ9z9EyPd\nzskYt2qMpm7DvjGjS4AfhPcTBGdw/mLYsh8gGCXQxr46Vpwx1MYqEXccMQtH1s8CXlvGbZ1scYtH\nOI1l5MekiTuOmI0V2tYJGbeabiPdUQmCeZY/T1B3upiik34IDjxsBs4req6Z4PTa+wgORMwZwx+o\n7HHHGfP+Cm3rZIs7oT5TE/SzPKG2tZJxq/E2kp11HvAIwZldbwduJ5g463ng9KLl3gX8sejxm4AM\nwXjQGWP4I5U97mTaVsWt7biTaVsrGbdabyPZYS8G3lr0+OvhzrkceCB8LkZQz/op+074uRQ4d8wr\nVoG4k2lbFbe2406mba1k3Gq9jWSHNRKMTy7UrS4DPhfefxh4b3h/OfDjyFasAnEn07Yqbm3HnUzb\nWsm41Xo74nBHd+9397TvG7/5CoITfQCuAI43s18TXKP0Qdg3PGg8KhF3Mm2r4tZ23Mm0rZWMW7VG\n8Y0YJ/gp81v2XSVlEcGZXOdQNONclLdKxJ1M26q4tR13Mm1rJeNW2200JyjlCeZe2Q4sDb/9Pgrk\n3f0OD2ecK4FKxJ1M26q4tR13Mm1rJeNWl1F+G55BsOPuAN5Wrm+fSsSdTNuquLUddzJtayXjVtNt\nVGeemtk84K3AlzyYF6QsKhF3Mm2r4tZ23Mm0rZWMW01GPaWAiIhUt4pezFpERKKnxC4iUmOU2EVE\naowSu4hIjVFiFxGpMUrsMimYWc7MHjazlWb2iJn9nQWXQTvcezrN7M3lWkeRqCixy2Sx191PdfcT\nCeYReQ3w8SO8pxNQYpcJR+PYZVIws153by56vJDgQiHtwNHA9wkunQbwHne/y8zuAY4HngW+C3wF\nuBp4CcFMgl9z92vLthEiI6TELpPC8MQePrcLOA7oIZhLZMDMFhNM67rczF4CfMjdLwqXv5LgYgyf\nDq/zeifwRnd/tqwbI3IEiUqvgEgFFaZtTQJfNbNTgRzBtTIP5pUEE0u9IXzcRnBRaSV2qSpK7DIp\nhaWYHLCNoNa+FTiF4LjTwKHeRnDBhpvKspIiY6SDpzLpmFkH8G/AVz2oRbYBm909TzB5VDxctAdo\nKXrrTcC7zCwZtrPEzJoQqTLqsctk0WBmDxOUXbIEB0u/FL72deDnZvZG4I9AX/j8o0DWzB4BvgN8\nmWCkzIPh1Xe6gNeWawNERkoHT0VEaoxKMSIiNUaJXUSkxiixi4jUGCV2EZEao8QuIlJjlNhFRGqM\nEruISI1RYhcRqTH/H/iTg6vwRspFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ff66eb748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Mid'].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
