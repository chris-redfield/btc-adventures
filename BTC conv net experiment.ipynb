{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import quandl\n",
    "import numpy as np\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = quandl.get('BCHARTS/BITFINEXUSD') -> OLD BUGGY DATASET (OBD)\n",
    "#data = quandl.get('BITFINEX/BTCUSD')\n",
    "#data = quandl.get('BITFINEX/XRPBTC')\n",
    "data = quandl.get('BITFINEX/ETHBTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Mid</th>\n",
       "      <th>Last</th>\n",
       "      <th>Bid</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-14</th>\n",
       "      <td>0.050580</td>\n",
       "      <td>0.028241</td>\n",
       "      <td>0.031181</td>\n",
       "      <td>0.031103</td>\n",
       "      <td>0.031102</td>\n",
       "      <td>0.031260</td>\n",
       "      <td>111142.045174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-15</th>\n",
       "      <td>0.032004</td>\n",
       "      <td>0.027950</td>\n",
       "      <td>0.031298</td>\n",
       "      <td>0.031399</td>\n",
       "      <td>0.031207</td>\n",
       "      <td>0.031390</td>\n",
       "      <td>62965.262239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-16</th>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.030690</td>\n",
       "      <td>0.030690</td>\n",
       "      <td>0.030709</td>\n",
       "      <td>55947.825399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-17</th>\n",
       "      <td>0.030989</td>\n",
       "      <td>0.024759</td>\n",
       "      <td>0.026878</td>\n",
       "      <td>0.026816</td>\n",
       "      <td>0.026821</td>\n",
       "      <td>0.026935</td>\n",
       "      <td>94445.983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-18</th>\n",
       "      <td>0.026960</td>\n",
       "      <td>0.020150</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>0.026509</td>\n",
       "      <td>0.026506</td>\n",
       "      <td>0.026605</td>\n",
       "      <td>141106.891752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                High       Low       Mid      Last       Bid       Ask  \\\n",
       "Date                                                                     \n",
       "2016-03-14  0.050580  0.028241  0.031181  0.031103  0.031102  0.031260   \n",
       "2016-03-15  0.032004  0.027950  0.031298  0.031399  0.031207  0.031390   \n",
       "2016-03-16  0.033500  0.030465  0.030700  0.030690  0.030690  0.030709   \n",
       "2016-03-17  0.030989  0.024759  0.026878  0.026816  0.026821  0.026935   \n",
       "2016-03-18  0.026960  0.020150  0.026555  0.026509  0.026506  0.026605   \n",
       "\n",
       "                   Volume  \n",
       "Date                       \n",
       "2016-03-14  111142.045174  \n",
       "2016-03-15   62965.262239  \n",
       "2016-03-16   55947.825399  \n",
       "2016-03-17   94445.983815  \n",
       "2016-03-18  141106.891752  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape before embedding: (653, 7)\n",
      "data shape after embedding: (646, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"data shape before embedding:\",data.shape)\n",
    "\n",
    "mean = data.mean(axis=0)\n",
    "std = data.std(axis=0)\n",
    "\n",
    "# zscore normalization\n",
    "data = ( data - mean ) / std\n",
    "\n",
    "# # of days past we want skynet to see\n",
    "d = 7\n",
    "\n",
    "X = np.zeros((data.shape[0],d,data.shape[1]))\n",
    "\n",
    "# embedding d days in each DP (deslocamento)\n",
    "for i in range(d,data.shape[0]):\n",
    "    X[i,:,:] = data.iloc[i-d:i].values\n",
    "\n",
    "#removing first d lines, this ones didn't have d days past\n",
    "X = X[d:,:,:]\n",
    "\n",
    "print(\"data shape after embedding:\",X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating labels\n",
    "Y = data['Mid'] - data.shift(1)['Mid']\n",
    "\n",
    "Y = Y > 0\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing first line: second label refers to first DP ($$ delta)\n",
    "Y = Y[1:]\n",
    "\n",
    "#removing first d days because of the embedding\n",
    "Y = Y[d:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing last registry from X, since we had to remove first DP from Y\n",
    "#specifying other dimensions for good practices - TY @lucasosouza\n",
    "X = X[: -1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((645,), (645, 7, 7))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shapes\n",
    "Y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(645, 7, 7, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding channel layer, as expected by the convnet\n",
    "X = X.reshape((Y.shape[0],d,7,1))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "#X_train = X[:-300,:,:,:]\n",
    "#X_test = X[-300:,:,:,:]\n",
    "#Y_train = Y[:-300]\n",
    "#Y_test = Y[-300:]\n",
    "\n",
    "# split dat data \n",
    "kf = KFold(n_splits=8,shuffle=True,random_state=0)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #padding same so we dont lose size\n",
    "    X = Conv2D(32,(3,3), strides=(1,1),name=\"conv0\", padding=\"same\")(X_input)\n",
    "    X = BatchNormalization(axis=3,name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    #X = MaxPooling2D((2,2),name='max_pool0')(X)\n",
    "    \n",
    "    #Second conv\n",
    "    X = Conv2D(64,(2,2), strides=(1,1),name=\"conv1\", padding=\"same\")(X)\n",
    "    X = BatchNormalization(axis=3,name='bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    #X = MaxPooling2D((2,2),name='max_pool1')(X)\n",
    "    \n",
    "    #Third conv\n",
    "    X = Conv2D(128,(1,1), strides=(1,1),name=\"conv2\", padding=\"same\")(X)\n",
    "    X = BatchNormalization(axis=3,name='bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #fcs\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(128,activation=\"relu\")(X)\n",
    "    #X = Dropout(rate=0.3, seed=0)(X)\n",
    "    X = Dense(64,activation=\"relu\")(X)\n",
    "    #X = Dropout(rate=0.3, seed=0)(X)\n",
    "    X = Dense(32,activation=\"relu\")(X)\n",
    "    #X = Dropout(rate=0.3, seed=0)(X)\n",
    "    X = Dense(1,activation=\"sigmoid\")(X)\n",
    "    \n",
    "    model = Model(inputs=X_input,outputs=X, name=\"model1\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.8151 - acc: 0.4655\n",
      "Epoch 2/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.7043 - acc: 0.5434\n",
      "Epoch 3/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.6994 - acc: 0.5239\n",
      "Epoch 4/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.6784 - acc: 0.5752\n",
      "Epoch 5/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.6863 - acc: 0.5858\n",
      "Epoch 6/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.6734 - acc: 0.6088\n",
      "Epoch 7/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.6876 - acc: 0.5487\n",
      "Epoch 8/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.6650 - acc: 0.5788\n",
      "Epoch 9/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.6637 - acc: 0.5858\n",
      "Epoch 10/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.6487 - acc: 0.6124\n",
      "Epoch 11/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.6450 - acc: 0.6142\n",
      "Epoch 12/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.6443 - acc: 0.6177\n",
      "Epoch 13/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.6127 - acc: 0.6832\n",
      "Epoch 14/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.6452 - acc: 0.6354\n",
      "Epoch 15/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.6361 - acc: 0.6496\n",
      "Epoch 16/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.6144 - acc: 0.6655\n",
      "Epoch 17/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.6062 - acc: 0.6496\n",
      "Epoch 18/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.5735 - acc: 0.6761\n",
      "Epoch 19/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.5862 - acc: 0.6655\n",
      "Epoch 20/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.5742 - acc: 0.6708\n",
      "Epoch 21/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.5561 - acc: 0.7080\n",
      "Epoch 22/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.5820 - acc: 0.6690\n",
      "Epoch 23/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.5429 - acc: 0.7150\n",
      "Epoch 24/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.5378 - acc: 0.7274\n",
      "Epoch 25/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.5110 - acc: 0.7310\n",
      "Epoch 26/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.5237 - acc: 0.7150\n",
      "Epoch 27/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.4745 - acc: 0.7398\n",
      "Epoch 28/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.4767 - acc: 0.7611\n",
      "Epoch 29/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.4735 - acc: 0.7504\n",
      "Epoch 30/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.4676 - acc: 0.7646\n",
      "Epoch 31/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.4172 - acc: 0.7681\n",
      "Epoch 32/200\n",
      "565/565 [==============================] - 2s 3ms/step - loss: 0.4530 - acc: 0.7664\n",
      "Epoch 33/200\n",
      "565/565 [==============================] - 2s 3ms/step - loss: 0.4242 - acc: 0.7929\n",
      "Epoch 34/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.4385 - acc: 0.7681\n",
      "Epoch 35/200\n",
      "565/565 [==============================] - 2s 3ms/step - loss: 0.3968 - acc: 0.8071\n",
      "Epoch 36/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.3591 - acc: 0.8177\n",
      "Epoch 37/200\n",
      "565/565 [==============================] - 2s 3ms/step - loss: 0.3925 - acc: 0.8000\n",
      "Epoch 38/200\n",
      "565/565 [==============================] - 2s 3ms/step - loss: 0.3516 - acc: 0.8106\n",
      "Epoch 39/200\n",
      "565/565 [==============================] - 2s 3ms/step - loss: 0.4369 - acc: 0.7823\n",
      "Epoch 40/200\n",
      "565/565 [==============================] - 2s 3ms/step - loss: 0.3667 - acc: 0.8142\n",
      "Epoch 41/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.3681 - acc: 0.8195\n",
      "Epoch 42/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.3459 - acc: 0.8106\n",
      "Epoch 43/200\n",
      "565/565 [==============================] - 2s 3ms/step - loss: 0.3202 - acc: 0.8336\n",
      "Epoch 44/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.2932 - acc: 0.8531\n",
      "Epoch 45/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.3138 - acc: 0.8442\n",
      "Epoch 46/200\n",
      "565/565 [==============================] - 2s 3ms/step - loss: 0.3287 - acc: 0.8442\n",
      "Epoch 47/200\n",
      "565/565 [==============================] - 2s 3ms/step - loss: 0.3053 - acc: 0.8619\n",
      "Epoch 48/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.2495 - acc: 0.8814\n",
      "Epoch 49/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.2430 - acc: 0.8956\n",
      "Epoch 50/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.3316 - acc: 0.8531\n",
      "Epoch 51/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.2641 - acc: 0.8814\n",
      "Epoch 52/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.2278 - acc: 0.8920A: 0s - loss: 0.2186 - ac\n",
      "Epoch 53/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.2219 - acc: 0.8903\n",
      "Epoch 54/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.2330 - acc: 0.9009\n",
      "Epoch 55/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.2839 - acc: 0.8796\n",
      "Epoch 56/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.2209 - acc: 0.8991\n",
      "Epoch 57/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1936 - acc: 0.9186\n",
      "Epoch 58/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1759 - acc: 0.9204\n",
      "Epoch 59/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1609 - acc: 0.9204\n",
      "Epoch 60/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1264 - acc: 0.9487\n",
      "Epoch 61/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1467 - acc: 0.9274\n",
      "Epoch 62/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.2513 - acc: 0.8991\n",
      "Epoch 63/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.2378 - acc: 0.8956\n",
      "Epoch 64/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1959 - acc: 0.9186\n",
      "Epoch 65/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1789 - acc: 0.9310\n",
      "Epoch 66/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1450 - acc: 0.9381\n",
      "Epoch 67/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1443 - acc: 0.9257\n",
      "Epoch 68/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1258 - acc: 0.9434\n",
      "Epoch 69/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1363 - acc: 0.9398\n",
      "Epoch 70/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1493 - acc: 0.9398\n",
      "Epoch 71/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.2395 - acc: 0.9150\n",
      "Epoch 72/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.2436 - acc: 0.9097\n",
      "Epoch 73/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1527 - acc: 0.9327\n",
      "Epoch 74/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1141 - acc: 0.9416\n",
      "Epoch 75/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1134 - acc: 0.9451\n",
      "Epoch 76/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0979 - acc: 0.9646\n",
      "Epoch 77/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0736 - acc: 0.9628\n",
      "Epoch 78/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1325 - acc: 0.9381\n",
      "Epoch 79/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1879 - acc: 0.9257\n",
      "Epoch 80/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.2218 - acc: 0.9115\n",
      "Epoch 81/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1469 - acc: 0.9345\n",
      "Epoch 82/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1015 - acc: 0.9558\n",
      "Epoch 83/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1089 - acc: 0.9611\n",
      "Epoch 84/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1071 - acc: 0.9646\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565/565 [==============================] - 3s 5ms/step - loss: 0.1218 - acc: 0.9469\n",
      "Epoch 86/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.1203 - acc: 0.9469\n",
      "Epoch 87/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1898 - acc: 0.9150\n",
      "Epoch 88/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1214 - acc: 0.9451\n",
      "Epoch 89/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0962 - acc: 0.9593\n",
      "Epoch 90/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0954 - acc: 0.9575\n",
      "Epoch 91/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0671 - acc: 0.9699\n",
      "Epoch 92/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0584 - acc: 0.9752\n",
      "Epoch 93/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0411 - acc: 0.9805\n",
      "Epoch 94/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0548 - acc: 0.9841\n",
      "Epoch 95/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0792 - acc: 0.9770\n",
      "Epoch 96/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.3270 - acc: 0.8814\n",
      "Epoch 97/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1652 - acc: 0.9434\n",
      "Epoch 98/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0693 - acc: 0.9770\n",
      "Epoch 99/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0556 - acc: 0.9805\n",
      "Epoch 100/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0449 - acc: 0.9788\n",
      "Epoch 101/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0495 - acc: 0.9805\n",
      "Epoch 102/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1620 - acc: 0.9487\n",
      "Epoch 103/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1080 - acc: 0.9487\n",
      "Epoch 104/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0893 - acc: 0.9646\n",
      "Epoch 105/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0719 - acc: 0.9717\n",
      "Epoch 106/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0474 - acc: 0.9805\n",
      "Epoch 107/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0467 - acc: 0.9735\n",
      "Epoch 108/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0468 - acc: 0.9788\n",
      "Epoch 109/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0263 - acc: 0.9912\n",
      "Epoch 110/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0338 - acc: 0.9858\n",
      "Epoch 111/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1073 - acc: 0.9575\n",
      "Epoch 112/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1584 - acc: 0.9469\n",
      "Epoch 113/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1105 - acc: 0.9664\n",
      "Epoch 114/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0558 - acc: 0.9841\n",
      "Epoch 115/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0351 - acc: 0.9876\n",
      "Epoch 116/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0200 - acc: 0.9947\n",
      "Epoch 117/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0142 - acc: 0.9965\n",
      "Epoch 118/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0157 - acc: 0.9929\n",
      "Epoch 119/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0184 - acc: 0.9912\n",
      "Epoch 120/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0230 - acc: 0.9912\n",
      "Epoch 121/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0304 - acc: 0.9858\n",
      "Epoch 122/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0269 - acc: 0.9912\n",
      "Epoch 123/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0479 - acc: 0.9805\n",
      "Epoch 124/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.1517 - acc: 0.9469\n",
      "Epoch 125/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.1610 - acc: 0.9416A: 0s - loss: 0.1672 - acc: 0\n",
      "Epoch 126/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1822 - acc: 0.9398\n",
      "Epoch 127/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1295 - acc: 0.9522\n",
      "Epoch 128/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.1029 - acc: 0.9699\n",
      "Epoch 129/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0335 - acc: 0.9894\n",
      "Epoch 130/200\n",
      "565/565 [==============================] - 3s 4ms/step - loss: 0.0241 - acc: 0.9912\n",
      "Epoch 131/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0243 - acc: 0.9965\n",
      "Epoch 132/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0150 - acc: 0.9982\n",
      "Epoch 133/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 134/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0076 - acc: 0.9982\n",
      "Epoch 135/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0095 - acc: 0.9982\n",
      "Epoch 136/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 137/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 138/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 139/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 140/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 141/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 142/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 143/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 144/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 145/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 146/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 147/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0167 - acc: 0.9929\n",
      "Epoch 148/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0763 - acc: 0.9770\n",
      "Epoch 149/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.4159 - acc: 0.8761\n",
      "Epoch 150/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.2039 - acc: 0.9239A: 0s - loss: 0.2369 \n",
      "Epoch 151/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0608 - acc: 0.9841\n",
      "Epoch 152/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1362 - acc: 0.9628\n",
      "Epoch 153/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0843 - acc: 0.9646\n",
      "Epoch 154/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1218 - acc: 0.9575\n",
      "Epoch 155/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0888 - acc: 0.9646\n",
      "Epoch 156/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0228 - acc: 0.9947\n",
      "Epoch 157/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0238 - acc: 0.9965\n",
      "Epoch 158/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0385 - acc: 0.9912\n",
      "Epoch 159/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0133 - acc: 0.9982\n",
      "Epoch 160/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0062 - acc: 1.0000A: 1s - lo\n",
      "Epoch 161/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 162/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 163/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 164/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 165/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0026 - acc: 1.0000A: 1s - loss: 0.0\n",
      "Epoch 166/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 167/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 169/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 170/200\n",
      "565/565 [==============================] - 3s 5ms/step - loss: 5.2885e-04 - acc: 1.0000\n",
      "Epoch 171/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 7.5410e-04 - acc: 1.0000\n",
      "Epoch 172/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 173/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0765 - acc: 0.9841\n",
      "Epoch 174/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.3814 - acc: 0.8903\n",
      "Epoch 175/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1932 - acc: 0.9239\n",
      "Epoch 176/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0738 - acc: 0.9752\n",
      "Epoch 177/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0357 - acc: 0.9929\n",
      "Epoch 178/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1148 - acc: 0.9823\n",
      "Epoch 179/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1113 - acc: 0.9717\n",
      "Epoch 180/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0594 - acc: 0.9876\n",
      "Epoch 181/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0556 - acc: 0.9770\n",
      "Epoch 182/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0432 - acc: 0.9876\n",
      "Epoch 183/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0191 - acc: 0.9965\n",
      "Epoch 184/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0204 - acc: 0.9912\n",
      "Epoch 185/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0117 - acc: 0.9965\n",
      "Epoch 186/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0081 - acc: 0.9982\n",
      "Epoch 187/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0278 - acc: 0.9947\n",
      "Epoch 188/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0088 - acc: 0.9965\n",
      "Epoch 189/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 190/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 191/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 192/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 193/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 6.4612e-04 - acc: 1.0000\n",
      "Epoch 194/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 5.8452e-04 - acc: 1.0000\n",
      "Epoch 195/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 196/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0048 - acc: 0.9965\n",
      "Epoch 197/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0343 - acc: 0.9947\n",
      "Epoch 198/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0029 - acc: 1.0000A: 0s - loss: 0.001\n",
      "Epoch 199/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.0089 - acc: 0.9947\n",
      "Epoch 200/200\n",
      "565/565 [==============================] - 2s 4ms/step - loss: 0.1057 - acc: 0.9664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8abc785908>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model, time for witchcraft\n",
    "model = model(X[0].shape)\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x = X_train, y = Y_train, epochs = 200, batch_size = 8,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 763us/step\n",
      "\n",
      "Loss = 4.02511167526\n",
      "Acc = 0.5\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(x = X_test, y = Y_test)\n",
    "print()\n",
    "print(\"Loss = \" + str(preds[0]))\n",
    "print(\"Acc = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8aba1d06a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEICAYAAABLdt/UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8abdbbf208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Mid'].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
